{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook for 5-anonymizing the Harvard Facebook dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset as a pandas dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assumes Harvard Facebook dataset stored in 105facebook.csv, \n",
    "# formatted and cleaned as described in paper (original version\n",
    "# before binning concentrations)\n",
    "df_init = pd.read_csv(\"105facebook.csv\")\n",
    "df_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop last row since NaN\n",
    "df = df_init.iloc[:-1 , :]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quasi_ids(df):\n",
    "    \"\"\"\n",
    "    Finds the quasi identifiers in the given dataframe,\n",
    "    which is all column names, except for 'Email' and 'Name'\n",
    "    \"\"\"\n",
    "    quasi_ids = df.columns.to_list()\n",
    "    quasi_ids.remove(\"Email\")\n",
    "    quasi_ids.remove(\"Name\")\n",
    "    return quasi_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['House', 'Year', 'Concentration']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get quasi_ids\n",
    "quasi_ids = get_quasi_ids(df)\n",
    "quasi_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for determining level of k-anonymity in a file\n",
    "# \n",
    "def level_k_anon(df, quasi_ids=quasi_ids):\n",
    "    \"\"\"\n",
    "    Determines the level of k anonymity the given dataframe has\n",
    "    for the given list of quasi identifier names.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: pandas DataFrame\n",
    "        df to find the level of anonymity of\n",
    "\n",
    "    quasi_ids: list\n",
    "        list of names of quasi identifiers (col names that correspond\n",
    "        to quasi identifiers)\n",
    "        NOTE: default is all column names except \"course_id\" and \"user_id\"\n",
    "    \"\"\"\n",
    "    # Group by set of quasi id values\n",
    "    quasi_id_grouped_df = df.groupby(quasi_ids, dropna=False)\n",
    "    # Get number of rows in each gruop\n",
    "    grouped_row_counts = quasi_id_grouped_df.size()\n",
    "    # Min number of rows in a group = level of k-anonymity\n",
    "    level_k_anon_num = min(grouped_row_counts)\n",
    "    return level_k_anon_num\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Determine the level of k-anonymity in the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_level_k_anon = level_k_anon(df)\n",
    "original_level_k_anon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Result:** the datframe is currently 1-anonymous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Make file anonymous using record suppression.**  (Assuming records are rows)\n",
    "\n",
    "**Question:** how many records need to be deleted to do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num of records dropped: 2735\n"
     ]
    }
   ],
   "source": [
    "num_records_dropped = 0\n",
    "# Group the dataframe by each unique set of quasi id values\n",
    "df_grouped_by_quasi_ids = df.groupby(quasi_ids, dropna=False)\n",
    "# Iterate through each group, removing any with < 5 entries\n",
    "for name, group in df_grouped_by_quasi_ids:\n",
    "    # print(name)\n",
    "    # print(group)\n",
    "    # Get size of group\n",
    "    group_size = group.shape[0]\n",
    "    # print(f\"num of rows in group: {group_size}\")\n",
    "    if group_size < k:\n",
    "        # print(\"group size < 0\")\n",
    "        # Record how many entries were removed when the group was removed\n",
    "        num_records_dropped += group_size\n",
    "    # print(\"\\n\")\n",
    "\n",
    "print(f\"total num of records dropped: {num_records_dropped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify results\n",
    "# Group by all the quasi ids\n",
    "group_by_quasi_ids_df = df.groupby(quasi_ids, dropna=False)\n",
    "# Get number of rows in each gruop\n",
    "grouped_row_counts = group_by_quasi_ids_df.size()\n",
    "print(grouped_row_counts)\n",
    "\n",
    "# Get number of rows who belong to a group of quasi ids with less than k members\n",
    "print(f\"k: {k}\")\n",
    "num_rows_less_than_k = grouped_row_counts[grouped_row_counts < k ].sum(skipna=False) \n",
    "print(f\"num rows with less than k duplicates: {num_rows_less_than_k}\")\n",
    "num_rows_greater_than_k = grouped_row_counts[grouped_row_counts >= k ].sum(skipna=False) \n",
    "print(f\"num rows with > or = to k duplicates: {num_rows_greater_than_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Result**: 2735 records were deleted to make the dataset 5-anonymous using record supression... This is clearly not a viable solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Make the file 5-anonymous using only column suppression**\n",
    "\n",
    "**Question:** How many columns are needed to do this, and which ones are they? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col for House has a min value count of 123\n",
      "col for Year has a min value count of 49\n",
      "col for Concentration has a min value count of 1\n",
      "cols removed: ['Concentration']\n",
      "num cols removed: 1\n"
     ]
    }
   ],
   "source": [
    "# Step 1: group by each col, throw out cols that results in groups with < k rows\n",
    "cols_removed = []\n",
    "for quasi_id in quasi_ids:\n",
    "    # Isolate just the column for a particular quasi id\n",
    "    col_df = df[quasi_id]\n",
    "    # Count the number of occurrences (counts) of each unique value in it\n",
    "    count = df[quasi_id].value_counts()\n",
    "    # print(count)\n",
    "    # Get the minimum number of occurrences of a unique value (min count at end)... \n",
    "    # if this is < 5, this record must be dropped\n",
    "    min_count = count.iloc[-1]\n",
    "    print(f\"col for {quasi_id} has a min value count of {min_count}\")\n",
    "    if (min_count < k):\n",
    "        cols_removed.append(quasi_id)\n",
    "\n",
    "print(f\"cols removed: {cols_removed}\")\n",
    "print(f\"num cols removed: {len(cols_removed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: check if reached 5-anonymity\n",
    "init_cols_supressed_df = df.drop(cols_removed,axis=1)\n",
    "# Checking that dropped all 11 desired cols\n",
    "print(f\"init cols supressed df: \\n{init_cols_supressed_df}\")\n",
    "# Check level of anonymity in remaining df\n",
    "sup_quasi_ids = get_quasi_ids(init_cols_supressed_df)\n",
    "print(f\"Quasi ids of col supressed df: {sup_quasi_ids}\")\n",
    "init_col_sup_lvl_anon = level_k_anon(init_cols_supressed_df, quasi_ids=sup_quasi_ids)\n",
    "print(f\"Level of k anonymity of dataframe after step 1: {init_col_sup_lvl_anon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Result:** 1 column has to be dropped.  This is: 'Concentration'.  The level of k-anonymity after dropping this column is 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory: what is the level of anonymity if we drop the column with the 2nd-smallest level of duplicates as well?\n",
    "explor_cols_supressed_df = df.drop(cols_removed + [\"House\"],axis=1)\n",
    "# Checking that dropped all 11 desired cols\n",
    "print(f\"explor cols supressed df: \\n{explor_cols_supressed_df}\")\n",
    "# Check level of anonymity in remaining df\n",
    "sup_quasi_ids2 = get_quasi_ids(explor_cols_supressed_df)\n",
    "print(f\"Quasi ids of col supressed df: {sup_quasi_ids2}\")\n",
    "explor_col_sup_lvl_anon = level_k_anon(explor_cols_supressed_df, quasi_ids=sup_quasi_ids2)\n",
    "print(f\"Level of k anonymity of dataframe after exploring deleting 'Concentration' and 'House': {explor_col_sup_lvl_anon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Produce a 5-anonymous dataset using generalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was done by generalizing \"Concentration\" into the following bins:\n",
    "\n",
    "\n",
    "*Arts*:\n",
    "\n",
    "* Art, Film, and Visual Studies\n",
    "* Music\n",
    "* Theater, Dance, & Media\n",
    "\n",
    "\n",
    "*Engineering*:\n",
    "\n",
    "* Biomedical Engineering\n",
    "* Electrical Engineering\n",
    "* Engineering Sciences\n",
    "* Environmental Science and Engineering\n",
    "* Mechanical Engineering\n",
    "\n",
    "\n",
    "*History*:\n",
    "\n",
    "* Anthropology\n",
    "* Classics\n",
    "* East Asian Studies\n",
    "* History\n",
    "* History and Literature\n",
    "* History and Science\n",
    "* History of Art and Architecture\n",
    "* South Asian Studies\n",
    "\n",
    "\n",
    "*Languages, Literatures, and Religion*:\n",
    "\n",
    "* Comparative Literature\n",
    "* Comparative Study of Religion\n",
    "* English\n",
    "* Folklore and Mythology\n",
    "* Germanic Languages and Literature\n",
    "* Linguistics\n",
    "* Near Eastern Languages and Civilizations\n",
    "* Romance Languages and Literature\n",
    "* Slavic Literatures and Cultures\n",
    "\n",
    "\n",
    "*Life Sciences*:\n",
    "\n",
    "* Chemical and Physical Biology\n",
    "* Human Developmental and Regenerative Biology\n",
    "* Human Evolutionary Biology\n",
    "* Integrative Biology\n",
    "* Molecular and Cellular Biology\n",
    "* Neuroscience\n",
    "* Psychology\n",
    "\n",
    "\n",
    "*Math and Computation*:\n",
    "\n",
    "* Applied Math\n",
    "* Computer Science\n",
    "* Mathematics\n",
    "* Statistics\n",
    "\n",
    "\n",
    "*Physical Sciences*:\n",
    "\n",
    "* Astrophysics\n",
    "* Chemistry\n",
    "* Chemistry and Physics\n",
    "* Earth and Planetary Sciences\n",
    "* Physics\n",
    "\n",
    "\n",
    "*Qualitative Social Sciences*:\n",
    "\n",
    "* African and African American Studies\n",
    "* Government\n",
    "* Philosophy\n",
    "* Social Studies\n",
    "* Studies of Women, Gender, and Sexuality\n",
    "\n",
    "\n",
    "*Quantitative Social Sciences*:\n",
    "* Economics\n",
    "* Environmental Science and Public Policy\n",
    "* Sociology\n",
    "* Special Concentration\n",
    "\n",
    "\n",
    "\n",
    "Note: this was done inside of Excel instead of in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the dataset with the binned concentrations\n",
    "binned_df = pd.read_csv(\"105facebookbins.csv\")\n",
    "binned_df = binned_df.iloc[:-1 , :] # Drop last col bc nan\n",
    "binned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['House', 'Year', 'ConcentrationBin']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the level of k-anonymity\n",
    "binned_quasi_ids = get_quasi_ids(binned_df)\n",
    "# remove \"Concentration\" as quasi id, as now looking at binned quasi ids\n",
    "binned_quasi_ids.remove(\"Concentration\")\n",
    "binned_quasi_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_anon_binned = level_k_anon(binned_df, binned_quasi_ids)\n",
    "k_anon_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of binning concentrations: still 1-anonymous..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking where the issue was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouped_row_counts(df, cols):\n",
    "    grouped_df = df.groupby(cols, dropna=False)\n",
    "    return grouped_df.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_dict = get_grouped_row_counts(binned_df, binned_quasi_ids).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When examining by eye, it appears that joint/double concentrations in different bins are primarily causing the problem (there are a bunch of joint/double concentrations and pretty much all of them have < 5 people in their grouping, with many of them having only 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are still some non-joint/double concentration people with < 5-anonymity, here's an example of someone who was 1-anonymous:\n",
    "\n",
    "('Adams', 'Senior', 'Arts'): 1,\n",
    "\n",
    "('Dunster', 'Sophomore', 'Arts'): 1,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two routes: bin by house in addition to concentration (necessary due to case of the Adams Senior above), and if this doesn't work: bin by house in addition to concentration AND remove the allied joint/double concentration, or bin by house in addition to by concentration\n",
    "\n",
    "Note: have to keep binning by concentration because concentration column alone leads to 1-anonymity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***4.1: Binning Houses in Addition to Concentrations***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings between each house and the bin it falls into\n",
    "mappings = {\n",
    "    \"Dudley\":\"Quad\",\n",
    "    \"Currier\":\"Quad\",\n",
    "    \"Pforzheimer\":\"Quad\",\n",
    "    \"Cabot\":\"Quad\",\n",
    "    \"Dunster\":\"River East\",\n",
    "    \"Mather\":\"River East\",\n",
    "    \"Leverett\":\"River East\",\n",
    "    \"Lowell\":\"River Central\",\n",
    "    \"Adams\":\"River Central\",\n",
    "    \"Quincy\":\"River Central\",\n",
    "    \"Winthrop\":\"River West\",\n",
    "    \"Eliot\":\"River West\",\n",
    "    \"Kirkland\":\"River West\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin by house in addition to concentration\n",
    "binned2_df = binned_df.copy()\n",
    "binned2_df[\"HouseBin\"] = binned2_df[\"House\"].map(mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year', 'ConcentrationBin', 'HouseBin']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the level of k-anonymity\n",
    "binned2_quasi_ids = get_quasi_ids(binned2_df)\n",
    "# remove \"Concentration\" as quasi id, as now looking at binned quasi ids\n",
    "binned2_quasi_ids.remove(\"Concentration\")\n",
    "binned2_quasi_ids.remove(\"House\")\n",
    "binned2_quasi_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_anon_binned2 = level_k_anon(binned2_df, binned2_quasi_ids)\n",
    "k_anon_binned2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of binning concentrations and houses: still 1-anonymous..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking where the issue was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_dict = get_grouped_row_counts(binned2_df, binned2_quasi_ids).to_dict()\n",
    "groups_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue seems to be coming from the joint/double concentrations...  removing the allied joint/double concentration \n",
    "\n",
    "Example of issue (note that there are lots of them):\n",
    "\n",
    "('Sophomore',\n",
    "  'Quantitative Social Sciences; Arts',\n",
    "  'River Central'): 1,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***4.2: Dropping Allied Joints/Second Double Concentrations on top of Binning Houses and Concentrations***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the house and concentration binned df on joint/double concentrations (separating\n",
    "# them into two different columns)\n",
    "binned3_df = binned2_df.copy()\n",
    "binned3_df[['ConcentrationBin_1', 'ConcentrationBin_2']] = binned2_df[\"ConcentrationBin\"].str.split('; ', expand=True)\n",
    "binned3_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year', 'HouseBin', 'ConcentrationBin_1']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the level of k-anonymity, using only Concentration_1\n",
    "binned3_quasi_ids = get_quasi_ids(binned3_df)\n",
    "# remove \"Concentration_2\" (as well as \"Concentration\" and \"House\" bc already binned)\n",
    "binned3_quasi_ids.remove(\"Concentration\")\n",
    "binned3_quasi_ids.remove(\"House\")\n",
    "binned3_quasi_ids.remove(\"ConcentrationBin_2\")\n",
    "binned3_quasi_ids.remove(\"ConcentrationBin\")\n",
    "binned3_quasi_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_anon_binned3 = level_k_anon(binned3_df, binned3_quasi_ids)\n",
    "k_anon_binned3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of binning concentrations and houses: still 1-anonymous..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking where issue was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_dict = get_grouped_row_counts(binned3_df, binned3_quasi_ids).to_dict()\n",
    "groups_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the issue was \"Special Concentration\" (several entries have 1 that have \"Special Concentration\", everything else looks fine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So removing Special Concentration (this is viable because survey respondents can just group themselves into the concentration bin that matches them best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***4.3 Removing Entries with Special Concentration***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year', 'HouseBin', 'ConcentrationBin_1']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binned4_quasi_ids = binned3_quasi_ids\n",
    "binned4_quasi_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows that contain 'Coca Cola'\n",
    "binned4_df = binned3_df.drop(binned3_df[binned3_df['ConcentrationBin_1'] == 'Special Concentration'].index)\n",
    "binned4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the level of k-anonymity\n",
    "k_anon_binned4 = level_k_anon(binned4_df, binned4_quasi_ids)\n",
    "k_anon_binned4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: the Harvard Facebook dataset is now 5-anonymous!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
